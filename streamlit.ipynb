{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nst.title('ì›Œë“œ ì„ë² ë”© í”„ë¡œì íŠ¸')\n\nDATE_COLUMN = 'date/time'\nDATA_URL = ('https://s3-us-west-2.amazonaws.com/'\n            'streamlit-demo-data/uber-raw-data-sep14.csv.gz')\n\n@st.cache\ndef load_data(nrows):\n    data = pd.read_csv(DATA_URL, nrows=nrows)\n    lowercase = lambda x: str(x).lower()\n    data.rename(lowercase, axis='columns', inplace=True)\n    data[DATE_COLUMN] = pd.to_datetime(data[DATE_COLUMN])\n    return data\n\ndata_load_state = st.text('Loading data...')\ndata = load_data(10000)\ndata_load_state.text(\"Done! (using st.cache)\")\n\n# if st.button(\"ë²„íŠ¼ í´ë¦­\"):\n#     st.write(\"Data Loading..\")\n#     # ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë™ì‘í•˜ê²Œ í•˜ê³  í•¨ìˆ˜ ì¶”ê°€\n\n# checkbox_btn1 = st.checkbox('ì˜µì…˜1')\n# checkbox_btn2 = st.checkbox('ì˜µì…˜2')\n\n# if checkbox_btn1:\n#     st.write('Great!')\n\n# if checkbox_btn2:\n#     st.write('Good!')\n\n# if st.checkbox('Show raw data'):\n#     st.subheader('Raw data')\n#     st.write(data)\n\n# multi_select = st.multiselect('Please select somethings in multi selectbox!',\n#                             ['A', 'B', 'C', 'D'])\n\n# st.write('You selected:', multi_select)\n\n# st.subheader('Number of pickups by hour')\n# hist_values = np.histogram(data[DATE_COLUMN].dt.hour, bins=24, range=(0,24))[0]\n# st.bar_chart(hist_values)\n\n# hour_to_filter = st.slider('hour', 0, 23, 17)\n# filtered_data = data[data[DATE_COLUMN].dt.hour == hour_to_filter]\n\n# st.subheader('Map of all pickups at %s:00' % hour_to_filter)\n# st.map(filtered_data)\n\n################################\n\n# íŒŒì¼ ê²½ë¡œ\nTENSOR_FILE = \"ko_w2v_tensor_asmr.tsv\"\nMETA_FILE = \"ko_w2v_metadata_asmr.tsv\"\n\n@st.cache_data\ndef load_model():\n    # ë©”íƒ€ë°ì´í„° (ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸)\n    words = pd.read_csv(META_FILE, sep=\"\\t\", header=None)[0].tolist()\n\n    # í…ì„œ (ë²¡í„° ë¦¬ìŠ¤íŠ¸)\n    vectors = np.loadtxt(TENSOR_FILE, delimiter=\"\\t\")\n\n    # ë‹¨ì–´-ë²¡í„° ë”•ì…”ë„ˆë¦¬ë¡œ ë§Œë“¤ê¸°\n    word_to_vec = {word: vec for word, vec in zip(words, vectors)}\n    return word_to_vec, words, vectors\n\nword_to_vec, words, vectors = load_model()\n\n# UI\nst.title(\"ğŸ” Word2Vec ìœ ì‚¬ ë‹¨ì–´ ê²€ìƒ‰ê¸° (ASMR ëŒ“ê¸€ ê¸°ë°˜)\")\nquery = st.text_input(\"ë‹¨ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:\")\n\nif query:\n    if query not in word_to_vec:\n        st.error(\"í•´ë‹¹ ë‹¨ì–´ëŠ” ë‹¨ì–´ì¥ì— ì—†ìŠµë‹ˆë‹¤.\")\n    else:\n        query_vec = word_to_vec[query].reshape(1, -1)\n        sims = cosine_similarity(query_vec, vectors)[0]\n        top_n = 10\n\n        top_idx = sims.argsort()[::-1][1:top_n+1]  # ìê¸° ìì‹  ì œì™¸\n        st.write(\"ìœ ì‚¬í•œ ë‹¨ì–´ë“¤:\")\n        for i in top_idx:\n            st.write(f\"{words[i]}: {sims[i]:.4f}\")\n\n# cosine_similarity\n\nst.markdown(\"---\")\nst.subheader(\"ììœ ë¡œìš´ ë‹¨ì–´ ì—°ì‚° (ì˜ˆ: ì„œìš¸ - í•œêµ­ + ì¼ë³¸ + ìŒì‹ - ë°°ê³ í””)\")\n\nexpression = st.text_input(\"ë‹¨ì–´ ì—°ì‚°ì‹\", \"\")\n\nif expression:\n    try:\n        tokens = expression.strip().split()\n\n        positive = []\n        negative = []\n        op = \"+\"  # ê¸°ë³¸ì€ ë”í•˜ê¸°\n\n        for token in tokens:\n            if token in [\"+\", \"-\"]:\n                op = token\n            else:\n                if token not in word_to_vec:\n                    st.error(f\"ë‹¨ì–´ '{token}'ê°€ ë‹¨ì–´ì¥ì— ì—†ìŠµë‹ˆë‹¤.\")\n                    break\n                if op == \"+\":\n                    positive.append(token)\n                elif op == \"-\":\n                    negative.append(token)\n\n        if positive:\n            vec_result = sum([word_to_vec[w] for w in positive])\n            if negative:\n                vec_result -= sum([word_to_vec[w] for w in negative])\n            vec_result = vec_result.reshape(1, -1)\n\n            sims = cosine_similarity(vec_result, vectors)[0]\n            top_idx = sims.argsort()[::-1][:5]\n\n            st.write(f\"ì—°ì‚° ê²°ê³¼:\")\n            for i in top_idx:\n                st.write(f\"{words[i]}: {sims[i]:.4f}\")\n        else:\n            st.warning(\"â•ì— í•´ë‹¹í•˜ëŠ” ë‹¨ì–´ê°€ 1ê°œ ì´ìƒ ìˆì–´ì•¼ í•´ìš”.\")\n\n    except Exception as e:\n        st.error(f\"ì—ëŸ¬ ë°œìƒ: {e}\")\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}